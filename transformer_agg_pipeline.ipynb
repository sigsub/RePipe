{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer aggregation inference example. Scientific papers dataset and the finetuned mpnet model combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_agg_net(\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from loading_paper_utils import load_data_from_pkl, embed_col, embed_text_list_col\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import torch\n",
    "from transformer_agg import transformer_agg_net, PaperVecPairsDataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*To copy construct from a tensor.*\")\n",
    "\n",
    "def run_trans_agg_embed(df_with_embedded_text_list_col, embedded_text_list_col_name, agg_model, max_len, agg_model_name, vec_shape=768):\n",
    "    df_with_embedded_text_list_col[embedded_text_list_col_name] = df_with_embedded_text_list_col[embedded_text_list_col_name].apply(lambda x: torch.tensor(x))\n",
    "    # print(df_with_embedded_text_list_col[embedded_text_list_col_name].iloc[0].shape[0])\n",
    "    df_with_embedded_text_list_col['padding_indicator'] = df_with_embedded_text_list_col[embedded_text_list_col_name].apply(lambda x: torch.cat((torch.zeros(x.shape[0]), torch.ones(max_len - x.shape[0]))))\n",
    "    df_with_embedded_text_list_col[embedded_text_list_col_name] = df_with_embedded_text_list_col[embedded_text_list_col_name].apply(lambda x: torch.cat((x, torch.zeros((max_len - x.shape[0], vec_shape))), dim=0))\n",
    "    df_with_embedded_text_list_col[f'{agg_model_name}_agg_outs_tuple'] = df_with_embedded_text_list_col.apply(lambda x: agg_model((x[embedded_text_list_col_name].unsqueeze(0), x['padding_indicator'].unsqueeze(0))), axis=1)\n",
    "    df_with_embedded_text_list_col[f'{agg_model_name}_agg_rep'] = df_with_embedded_text_list_col[f'{agg_model_name}_agg_outs_tuple'].apply(lambda x: x[0].squeeze().cpu().detach().numpy())\n",
    "\n",
    "sci_papers_mpnet_agg_model = transformer_agg_net(d_model=768, nhead=12, n_transformer_layers=2, dropout=0.1)\n",
    "sci_papers_mpnet_agg_model.load_state_dict(torch.load('TRAINED/MODEL/SAVE/PATH', weights_only=True))\n",
    "sci_papers_mpnet_agg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_papers_train_set = load_data_from_pkl('/PATH/TO/TRAIN/PKL/OF/DATA/PREPPED/FOR/TRANSFORMER/AGGREGATION')\n",
    "sci_papers_test_set = load_data_from_pkl('//PATH/TO/TEST/PKL/OF/DATA/PREPPED/FOR/TRANSFORMER/AGGREGATION')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_papers_max_len = sci_papers_train_set['pars_abstract_ft_e5_embedding'].apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCI PAPERS TRAIN SET\n",
      "Index(['id', 'title', 'abstract', 'category', 'html_path', 'pars', 'sections',\n",
      "       'num_pars', 'pars_abstract_ft_e5_embedding',\n",
      "       'pars_abstract_ft_all_mpnet_embedding'],\n",
      "      dtype='object')\n",
      "SCI PAPERS TEST SET\n",
      "Index(['id', 'title', 'abstract', 'category', 'html_path', 'pars', 'sections',\n",
      "       'num_pars', 'pars_abstract_ft_e5_embedding',\n",
      "       'pars_abstract_ft_all_mpnet_embedding'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('SCI PAPERS TRAIN SET')\n",
    "print(sci_papers_train_set.columns)\n",
    "print('SCI PAPERS TEST SET')\n",
    "print(sci_papers_test_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, name in [(sci_papers_train_set, 'sci_train'), (sci_papers_test_set, 'sci_test')]:\n",
    "    run_trans_agg_embed(df, 'pars_abstract_ft_all_mpnet_embedding', sci_papers_mpnet_agg_model, sci_papers_max_len, 'mpnet_trained_aggregator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "sci_papers columns mpnet_trained_aggregator_agg_rep sil: 0.9944777488708496\n",
      "TEST\n",
      "sci_papers columns mpnet_trained_aggregator_agg_rep sil: 0.5468906164169312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "print(\"TRAIN\")\n",
    "df = sci_papers_train_set\n",
    "name = 'sci_papers'\n",
    "for c in [x for x in df.columns if 'aggregator' in x and 'rep' in x]:\n",
    "    cat_conv = {cat:i for i, cat in enumerate(df['category'].unique())}\n",
    "    # print(df[c].iloc[0][0].squeeze().shape)\n",
    "    print(f'{name} columns {c} sil: {silhouette_score(df[c].tolist(), df[\"category\"].apply(lambda x: cat_conv[x]).tolist(), metric=\"cosine\")}')\n",
    "\n",
    "print(\"TEST\")\n",
    "df = sci_papers_test_set\n",
    "name = 'sci_papers'\n",
    "for c in [x for x in df.columns if 'aggregator' in x and 'rep' in x]:\n",
    "    cat_conv = {cat:i for i, cat in enumerate(df['category'].unique())}\n",
    "    # print(df[c].iloc[0][0].squeeze().shape)\n",
    "    print(f'{name} columns {c} sil: {silhouette_score(df[c].tolist(), df[\"category\"].apply(lambda x: cat_conv[x]).tolist(), metric=\"cosine\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids shape: (16, 768)\n"
     ]
    }
   ],
   "source": [
    "from data_refining_pipeline import train_df_to_centroids_v2, alg_for_par_selection, alg_for_par_selection_with_initial_cents\n",
    "\n",
    "sci_papers_cents_mpnet, sci_paper_cent_d_mpnet = train_df_to_centroids_v2(sci_papers_train_set, 'mpnet_trained_aggregator_agg_rep')\n",
    "sci_papers_train_set['mpnet_predicted_cent'] = sci_papers_train_set['mpnet_trained_aggregator_agg_rep'].apply(lambda x:\n",
    "                                                                                                        np.argmax(cosine_similarity([x], sci_papers_cents_mpnet)))\n",
    "\n",
    "sci_papers_test_set['mpnet_predicted_cent'] = sci_papers_test_set['mpnet_trained_aggregator_agg_rep'].apply(lambda x:\n",
    "                                                                                                        np.argmax(cosine_similarity([x], sci_papers_cents_mpnet)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 result for sci_papers df, mpnet_predicted_cent col, 0.5806770708609359\n"
     ]
    }
   ],
   "source": [
    "from matching_metrics import get_macro_f1\n",
    "\n",
    "df = sci_papers_test_set\n",
    "name = 'sci_papers'\n",
    "pred_col = 'mpnet_predicted_cent'        \n",
    "cat_d = {cat:i for i, cat in enumerate(df['category'].unique())}\n",
    "df['cat_id'] = df['category'].apply(lambda x: cat_d[x])\n",
    "pairs = pd.merge(df[[pred_col, 'category', 'id']], df[[pred_col, 'category', 'id']], how='cross', suffixes=('_1', '_2'))\n",
    "pairs['label'] = pairs.apply(lambda x: 1 if x['category_1'] == x['category_2'] else 0, axis=1)\n",
    "pairs['pred'] = pairs.apply(lambda x: 1 if x[f'{pred_col}_1'] == x[f'{pred_col}_2'] else 0, axis=1)\n",
    "print(f\"F1 result for {name} df, {pred_col} col, {get_macro_f1(pairs)[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultimate_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
